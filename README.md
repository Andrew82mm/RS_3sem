# KNN Implementations Comparison for Recommender Systems
Sergienko Andrew B-82 coursework
## ğŸ“Œ Introduction

This repository contains a modular and reproducible framework for comparing **exact** and **approximate** K-Nearest Neighbors algorithms in the context of **collaborative filtering recommender systems**.

The project includes:

* Data preprocessing and filtering of the MovieLens dataset
* Construction of sparse interaction matrices
* Dimensionality reduction using Truncated SVD
* Generation of user and item embeddings
* Unified implementations of four KNN algorithms:
  **Exact KNN**, **Annoy**, **FAISS**, **HNSW**
* Isolated benchmarking environment for accurate performance measurement
* Hyperparameter tuning for all ANN methods

The goal is to provide a complete and reproducible environment for testing nearest-neighbor search techniques in large-scale recommender systems.

---

## â–¶ï¸ How to Install and Run the Project

### 1. Clone the repository

```bash
git clone https://github.com/Andrew82mm/RS_3sem.git
cd RS_3sem
```

### 2. Create and activate a Python virtual environment

```bash
python3 -m venv venv
source venv/bin/activate           # Linux/macOS
venv\Scripts\activate              # Windows
```

### 3. Install all dependencies from `requirements.txt`

This installs:

* Annoy
* FAISS (CPU version if available)
* hnswlib
* scikit-learn
* pandas, numpy
* psutil for memory profiling
* and all other required modules

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

> âš ï¸ If you are on Windows and FAISS fails to install, use the CPU Windows build:

```bash
pip install faiss-cpu-windows
```

---

### 4. Prepare the dataset

Place MovieLens files into(or use a dataset from the repository): 

```
data/raw/movies.csv  
data/raw/ratings.csv
```

### 5. Generate embeddings (SVD)

```bash
python data.py
```

This step will:

* filter the dataset
* build the user-item CSR matrix
* compute SVD
* generate embeddings
* save processed data into `data/processed/`

---

### 6. Run hyperparameter tuning (optional)

```bash
python run_tuning.py
```

Generated files:

```
tuning/best_params.json
tuning/tuning_results.csv
```

---

### 7. Run the full KNN comparison benchmark

```bash
python run_comparison.py
```

This will:

* build all KNN indices
* run isolated benchmarking workers
* measure memory usage and timing
* compute accuracy against Exact KNN
* save results into `results/`

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ data
â”‚Â Â  â”œâ”€â”€ inf.md
â”‚Â Â  â”œâ”€â”€ processed
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ movie_embeddings_128d.csv
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ movie_embeddings_128d.npy
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ movie_id_mapping.pkl
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ svd_model.pkl
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ user_embeddings_128d.csv
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ user_embeddings_128d.npy
â”‚Â Â  â”‚Â Â  â””â”€â”€ user_id_mapping.pkl
â”‚Â Â  â””â”€â”€ raw
â”‚Â Â      â”œâ”€â”€ movies.csv
â”‚Â Â      â””â”€â”€ ratings.csv
â”œâ”€â”€ knn_comparison
â”‚Â Â  â”œâ”€â”€ annoy.py
â”‚Â Â  â”œâ”€â”€ base.py
â”‚Â Â  â”œâ”€â”€ bench.py
â”‚Â Â  â”œâ”€â”€ data.py
â”‚Â Â  â”œâ”€â”€ exact.py
â”‚Â Â  â”œâ”€â”€ faiss.py
â”‚Â Â  â”œâ”€â”€ hnsw.py
â”‚Â Â  â”œâ”€â”€ __init__.py
â”‚Â Â  â”œâ”€â”€ utils.py
â”‚Â Â  â””â”€â”€ viz.py
â”œâ”€â”€ notebooks
â”‚Â Â  â””â”€â”€ kursah32m.ipynb
â”œâ”€â”€ results
â”‚Â Â  â”œâ”€â”€ knn_comparison.png
â”‚Â Â  â””â”€â”€ knn_results.csv
â”œâ”€â”€ tex
â”‚Â Â  â”œâ”€â”€ Reportv1.pdf
â”‚Â Â  â”œâ”€â”€ Reportv1.tex
â”œâ”€â”€ tuning
â”‚   â”œâ”€â”€ best_params.json
â”‚   â””â”€â”€ tuning_results.csv
â”‚
â”œâ”€â”€ data.py
â”œâ”€â”€ run_comparison.py
â”œâ”€â”€ run_tuning.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ§­ Recommendations

* Use **HNSW** for real-time systems requiring fast queries and high accuracy.
* Use **FAISS** for large-scale environments or when GPU acceleration is available.
* Use **Annoy** for extremely fast filtering or low-latency tasks where slight accuracy loss is acceptable.
* Use **Exact KNN** only as a baseline for validation and evaluation.

---
