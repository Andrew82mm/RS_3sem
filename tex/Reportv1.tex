\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{indentfirst}

\geometry{
    a4paper,
    left=30mm,
    right=15mm,
    top=20mm,
    bottom=20mm
}

% Настройка гиперссылок
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    citecolor=black,
    filecolor=black,
    urlcolor=blue
}

% Переименование заголовков
\addto\captionsrussian{
    \renewcommand{\contentsname}{Оглавление}
    \renewcommand{\refname}{Список литературы}
}

% Настройка отступов
\setlength{\parindent}{1.25cm}
\setlength{\parskip}{0pt}

\begin{document}

% ============ ТИТУЛЬНЫЙ ЛИСТ ============
\begin{titlepage}
    \centering
    
    {\large САНКТ-ПЕТЕРБУРГСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ\par}
    \vspace{0.5cm}
    {\large Искусственный интеллект и наука о данных\par}
    
    \vspace{4cm}
    
    {\large Сергиенко Андрей\par}
    
    \vspace{2cm}
    
    {\Large\bfseries Применение алгоритмов K-ближайших соседей в коллаборативных рекомендательных системах\par}
    
    \vspace{0.5cm}
    
    {\large Отчёт о прохождении\\Учебной (ознакомительной) практики\par}
    
    \vfill
    
    \begin{flushright}
        Научный руководитель:\\
        Старший преподаватель кафедры системного программирования\\
        Юрий Александрович Андреев
    \end{flushright}
    
    \vfill
    
    {\large Санкт-Петербург\par}
    {\large 2025\par}
    
\end{titlepage}

% ============ ОГЛАВЛЕНИЕ ============
\newpage
\tableofcontents
\newpage

% ============ ВВЕДЕНИЕ ============
\section*{Введение}
\addcontentsline{toc}{section}{Введение}

Современные информационные системы ежедневно обрабатывают огромные объёмы данных, среди которых особое место занимают персонализированные рекомендации~--- фильмы, музыка, товары, новости и многое другое. Рекомендательные системы позволяют пользователям находить интересный контент, а компаниям~--- повышать вовлечённость и продажи.

Одним из наиболее популярных подходов к построению рекомендательных систем является коллаборативная фильтрация (Collaborative Filtering, CF), основанная на идее, что пользователи с похожими интересами будут оценивать похожие объекты схожим образом. Ключевой задачей коллаборативной фильтрации является поиск похожих пользователей или объектов, для чего широко применяется алгоритм K-ближайших соседей (K-Nearest Neighbors, KNN).

Однако точный поиск ближайших соседей имеют высокую вычислительную сложность и становится неэффективным при работе с большими наборами данных. Поэтому активно развиваются приближённые методы поиска ближайших соседей (Approximate Nearest Neighbors, ANN), такие как Annoy, FAISS и HNSW, обеспечивающие компромисс между скоростью и точностью.

Настоящая работа посвящена исследованию и сравнению эффективности различных реализаций алгоритма K-ближайших соседей в контексте коллаборативных рекомендательных систем.

\newpage

% ============ ПОСТАНОВКА ЗАДАЧИ ============
\section{Постановка задачи}

Цель работы~--- исследовать эффективность различных алгоритмов K-ближайших соседей для реализации коллаборативной рекомендательной системы, а также провести сравнительный анализ их производительности, точности и использования памяти.

Для достижения цели необходимо решить следующие задачи:

\begin{enumerate}
    \item Изучить основные принципы работы коллаборативной фильтрации и алгоритма K-ближайших соседей.
    \item Реализовать базовую рекомендательную систему на основе пользовательских и предметных матриц.
    \item Реализовать и сравнить четыре метода поиска ближайших соседей:
    \begin{itemize}
        \item Точный KNN (scikit-learn);
        \item Annoy (Spotify);
        \item FAISS (Meta);
        \item HNSW (Hierarchical Navigable Small World).
    \end{itemize}
    \item Провести измерения времени построения индекса, скорости запросов, точности (Recall@20, Precision@20) и использования памяти.
    \item Визуализировать результаты и сформулировать выводы о применимости каждого метода.
\end{enumerate}

\newpage

% ============ ОБЗОР ============
\section{Обзор}

\subsection{Обзор рекомендательных систем и их классификация}

Рекомендательные системы (RS) представляют собой программные системы, задача которых~--- предсказать интерес пользователя к объекту на основе анализа исторических данных. Существует три основных подхода к построению RS:

\begin{enumerate}
    \item \textbf{Контентная фильтрация} (Content-Based Filtering)~--- анализирует характеристики объектов и строит рекомендации, исходя из сходства контента.
    \item \textbf{Коллаборативная фильтрация} (Collaborative Filtering, CF)~--- основывается на взаимодействиях пользователей и объектов (рейтинги, покупки, клики).
    \item \textbf{Гибридные методы} (Hybrid Methods)~--- объединяют оба подхода для повышения качества рекомендаций.
\end{enumerate}

Коллаборативная фильтрация, в свою очередь, делится на:
\begin{itemize}
    \item \textbf{User-based CF}~--- рекомендации формируются на основе схожих пользователей;
    \item \textbf{Item-based CF}~--- рекомендации формируются на основе схожих объектов.
\end{itemize}

\subsection{Алгоритм K-ближайших соседей и его применение}

Алгоритм K-ближайших соседей (KNN) является одним из базовых методов в коллаборативной фильтрации. Он позволяет находить элементы, наиболее похожие на заданный, по метрике сходства (например, косинусное сходство или корреляция Пирсона).

В контексте рекомендательных систем:
\begin{itemize}
    \item В user-based CF ищутся пользователи, схожие по поведению с данным пользователем;
    \item В item-based CF~--- объекты, схожие с теми, что пользователь уже оценил.
\end{itemize}

Рекомендации формируются как взвешенное усреднение оценок ближайших соседей, что позволяет эффективно предсказывать предпочтения даже при отсутствии контентной информации.

\subsection{Проблемы масштабируемости и приближённые методы}

Основным недостатком точного KNN является высокая вычислительная сложность.

Пусть у нас:
\begin{itemize}
    \item $N$~--- количество объектов в базе
    \item $Q$~--- количество запросов
    \item $d$~--- размерность поискового пространства
    \item $K$~--- количество искомых соседей
\end{itemize}

Вычисление расстояния между двумя векторами требует $O(d)$.\\
Так как нужно сравнить со всеми $N$ точками, то $O(N \cdot d)$.\\
Для всех $Q$ запросов~--- $O(Q \cdot N \cdot d)$.\\
Используем алгоритм Quickselect~--- $O(N + K \log K)$.\\
После вычисления всех $N$ расстояний нужно выбрать $K$ наименьших~--- $O(Q \cdot (N \cdot d + K \log K))$.

При росте числа пользователей, запросов и объектов (например, в системах с миллионами записей) такой подход становится непрактичным.

Для решения этой проблемы используются Approximate Nearest Neighbors (ANN)~--- приближённые методы поиска, которые жертвуют небольшой долей точности ради значительного выигрыша в скорости.

ANN-методы строят специальные структуры данных (деревья, графы, хеши), что позволяет находить близкие элементы за логарифмическое или даже константное время.

\subsection{Существующие библиотеки поиска ближайших соседей}

Среди наиболее популярных библиотек для реализации ANN можно выделить:

\begin{itemize}
    \item \textbf{Annoy (Spotify)}~--- метод случайных проекций и построения деревьев, эффективен для больших векторов признаков.
    \item \textbf{FAISS (Meta)}~--- оптимизирована под большие данные и вычисления на GPU, активно используется в индустриальных решениях.
    \item \textbf{HNSW (Hierarchical Navigable Small World)}~--- графовая структура данных, обеспечивающая высокую точность и малое время отклика даже при миллионах элементов.
\end{itemize}

\subsection{Ожидаемые результаты}

В ходе работы будет реализован программный комплекс для сравнения точного и приближённых алгоритмов поиска ближайших соседей в коллаборативных системах рекомендаций.

Ожидается, что:
\begin{itemize}
    \item Точный KNN обеспечит наилучшую точность (Recall@20, Precision@20), но низкую производительность на больших данных;
    \item Annoy покажет компромисс между скоростью и точностью, потребляя умеренные ресурсы;
    \item FAISS продемонстрирует высокую скорость при больших объёмах данных, особенно с GPU;
    \item HNSW обеспечит оптимальный баланс между скоростью, точностью и памятью, являясь лучшим выбором для production-систем.
\end{itemize}

Результаты исследования будут представлены в виде таблиц и графиков, отражающих:
\begin{itemize}
    \item время построения индекса;
    \item среднее время запроса;
    \item использование оперативной памяти;
    \item показатели точности (Precision@20, Recall@20).
\end{itemize}

\newpage

% ============ ПРОЕКТИРОВАНИЕ ============
\section{Проектирование}

\subsection{Архитектура системы} 

Архитектура разработанной системы для генерации эмбеддингов рекомендательной системы построена по модульному принципу и состоит из следующих основных компонентов: 

\textbf{1. Модуль загрузки и предварительной обработки данных}
\begin{itemize}
	\item Загрузка датасета MovieLens (файлы movies.csv и ratings.csv).
	\item Удаление избыточных признаков (жанры фильмов, временные метки) для концентрации на данных взаимодействий.
	\item Первичная валидация и проверка целостности данных.
\end{itemize} 

\textbf{2. Модуль фильтрации и индексации данных}
\begin{itemize}
	\item Отбор активных пользователей (оставлены пользователи с более чем 50 оценок).
	\item Отбор популярных фильмов (оставлены фильмы с более чем 10 оценками).
	\item Создание непрерывных отображений (маппингов) для идентификаторов пользователей и фильмов в индексы матрицы, что позволяет избежать «пробелов» в индексации.
\end{itemize} 

\textbf{3. Модуль формирования разреженной матрицы взаимодействий}
\begin{itemize}
	\item Прямое формирование разреженной матрицы «пользователь-фильм» в формате CSR (Compressed Sparse Row) из отфильтрованных данных.
	\item Использование векторов оценок, индексов пользователей и фильмов для эффективного построения матрицы без создания промежуточных плотных структур.
\end{itemize} 

\textbf{4. Модуль матричной факторизации и генерации эмбеддингов}
\begin{itemize}
	\item Применение алгоритма TruncatedSVD из библиотеки Scikit-learn для выполнения матричной факторизации.
	\item Снижение размерности исходной разреженной матрицы до латентного пространства заданной размерности (128 компонентов).
	\item Генерация векторных представлений (эмбеддингов) для пользователей и фильмов как результатов разложения матрицы.
\end{itemize} 

\textbf{5. Модуль сохранения результатов и модели}
\begin{itemize}
	\item Сериализация полученных эмбеддингов в удобные для использования форматы (CSV для интерпретации, NumPy для быстрой загрузки).
	\item Сохранение созданных маппингов ID в индексы для последующего использования в сервисе рекомендаций.
	\item Сохранение обученной модели SVD для возможности ее дальнейшего использования или дообучения.
\end{itemize} 

\newpage

\textbf{6. Модуль реализации алгоритмов поиска}
\begin{itemize}
    \item Единый интерфейс для всех алгоритмов с методами build(), query\_user(), query\_item()
    \item Четыре независимые реализации: ExactKNN, AnnoyKNN, FAISSKNN, HNSWKNN
    \item Поддержка как user-based, так и item-based подходов
\end{itemize}

\textbf{7. Модуль мониторинга производительности}
\begin{itemize}
    \item Класс MemoryTracker для измерения потребления оперативной памяти
    \item Замеры времени построения индексов и выполнения запросов
    \item Использование библиотеки psutil для точного профилирования
\end{itemize}

\textbf{8. Модуль оценки точности}
\begin{itemize}
    \item Генерация тестовой выборки из 100 случайных запросов
    \item Сравнение результатов приближённых методов с эталонным Exact KNN
    \item Вычисление метрик Recall@20 и Precision@20
\end{itemize}

\textbf{9. Модуль визуализации и анализа}
\begin{itemize}
    \item Построение шести сравнительных графиков
    \item Сохранение результатов в CSV-формате
    \item Генерация текстового отчёта с рекомендациями
\end{itemize}

Взаимодействие между модулями организовано последовательно: данные проходят через этапы загрузки, обработки, построения индексов, тестирования и визуализации результатов.

\subsection{Выбор и подготовка датасета}

В качестве экспериментального датасета был выбран MovieLens(32m)~--- один из наиболее распространённых наборов данных для исследований в области рекомендательных систем. Датасет содержит:
\begin{itemize}
	\item Файл movies.csv: идентификаторы фильмов, названия и жанры.
	\item Файл ratings.csv: оценки пользователей (userId, movieId, rating, timestamp).
\end{itemize}

Преимущества выбранного датасета:
\begin{itemize}
	\item Реальные данные от пользователей сервиса MovieLens, что обеспечивает высокую внешнюю валидность результатов.
	\item Высокая разреженность, типичная для коллаборативных систем и представляющая ключевую вычислительную проблему.
\end{itemize}

На этапе предварительной обработки были выполнены следующие операции:

\textbf{Удаление избыточных признаков}: столбцы `genres` и `timestamp` были исключены, так как в данной работе исследуется исключительно коллаборативная фильтрация без использования контентных признаков.

\textbf{Фильтрация пользователей и объектов}: для повышения качества рекомендаций и уменьшения вычислительной сложности были отобраны только активные пользователи (с числом оценок $> 50$) и популярные фильмы (с числом оценок $> 10$). Это позволило снизить влияние шумовых взаимодействий и сосредоточиться на объектах с достаточным количеством информации для построения надёжных моделей. В результате было выделено 126 588 пользователей и 30 521 фильм.

\subsection{Формирование пользовательско-предметной матрицы}

Центральным элементом коллаборативной фильтрации является матрица взаимодействий <<пользователь--объект>>. В данной работе была сформирована матрица размерностью $126\,588 \times 30\,521$, где строки соответствуют пользователям, столбцы~--- фильмам, а значения~--- оценкам от 0.5 до 5.0. Показатель разреженности матрицы составил 99.24\% (плотность 0.76\%).

\textbf{Проблема плотного представления}

Теоретически можно построить плотную матрицу размера $126\,588 \times 30\,521$, заполнив отсутствующие оценки нулями или специальными значениями. Однако такой подход имеет ряд критических недостатков:
\begin{itemize}
	\item \textbf{Чрезмерные требования к памяти}: плотная матрица такого размера содержит более $3.86$ млрд элементов. При хранении в формате \texttt{float32} это потребовало бы порядка 15.5~ГБ памяти, что значительно превышает объём оперативной памяти большинства рабочих станций.
	\item \textbf{Шум из-за заполнения пропусков}: подавляющее большинство взаимодействий отсутствует, и заполнение нулями создаёт искусственные связи <<пользователь не любит этот фильм>>, хотя отсутствие оценки не означает отрицательное отношение.
	\item \textbf{Неэффективные вычисления}: большая часть операций (умножение матриц, вычисление расстояний) будет выполняться на бесполезных нулевых элементах.
\end{itemize}

\textbf{Преобразование в разреженный формат}

Для эффективной работы с высокоразреженными данными матрица была конвертирована в формат CSR (Compressed Sparse Row) с использованием библиотеки SciPy. Формат CSR хранит только ненулевые элементы и их индексы, что обеспечивает:
\begin{itemize}
	\item Существенную экономию памяти (в данном случае хранится лишь 0.76\% от полного объёма).
	\item Быструю индексацию строк и эффективное выполнение матричных операций, критически важных для последующих этапов.
\end{itemize}

\textbf{Почему разреженного формата недостаточно}

Несмотря на существенное снижение объёма данных, разреженная матрица остаётся крайне высокой размерности (десятки тысяч признаков на пользователя). Это приводит к следующим ограничениям:
\begin{itemize}
	\item \textbf{Проблема <<проклятия размерности>>}: вычисление расстояний или сходства между разреженными векторами с десятками тысяч измерений становится неинформативным --- большинство пар пользователей не имеют пересечения по оценённым фильмам.
	\item \textbf{Невозможность обобщения}: если два пользователя не оценили общие фильмы, методы на основе расстояний не смогут определить их сходство.
	\item \textbf{Высокие вычислительные затраты}: операции со столь широкими матрицами требуют значительных ресурсов, даже при хранении их в CSR-формате.
\end{itemize}

Эти ограничения делают невозможным эффективное использование разреженной матрицы напрямую для поиска соседей или построения рекомендаций. Поэтому применяется следующий этап: снижение размерности и генерация эмбеддингов.

\subsection{Снижение размерности и генерация эмбеддингов}

Чтобы получить компактное и информативное представление пользователей и фильмов, был применён подход матричной факторизации, позволяющий перейти от разреженного пространства исходных оценок к плотным низкоразмерным векторным представлениям~--- эмбеддингам.

\textbf{Концепция эмбеддингов}. Эмбеддинг представляет собой плотный вектор фиксированного размера (в данном случае 128), который кодирует сущность (пользователя или фильм) в непрерывном векторном пространстве. В отличие от разреженного представления, эмбеддинги не просто указывают на наличие взаимодействия, а захватывают его \textit{латентные (скрытые) признаки}. Для фильма это могут быть абстрактные характеристики, такие как <<уровень драматизма>>, <<научно-фантастичность>> или <<динамичность экшена>>. Для пользователя эмбеддинг отражает его предпочтения по этим же латентным осям.

\textbf{Преимущества использования эмбеддингов}:
\begin{itemize}
	\item \textbf{Снижение размерности}: Переход от пространства размерностью $30\,521$ (число фильмов) к пространству размерностью 128 значительно упрощает вычисления.
	\item \textbf{Вычислительная эффективность}: Расчёт метрик сходства в 128-мерном пространстве на порядки быстрее, чем в исходном разреженном пространстве.
	\item \textbf{Борьба с разреженностью}: Плотные векторы позволяют определять сходство даже между пользователями, не имеющими совместно оценённых фильмов.
	\item \textbf{Обобщение предпочтений}: Модель улавливает скрытые паттерны в поведении пользователей и структуре фильмов, сглаживая шум и исключая влияние единичных оценок.
	\item \textbf{Сжатие информации}: Эмбеддинги обеспечивают уменьшение числа признаков более чем в 200 раз и при этом сохраняют значимую часть дисперсии данных, что подтверждает эффективность кодирования.
\end{itemize}

\textbf{Технология реализации}. Для снижения размерности матрицы взаимодействий был использован метод усечённого сингулярного разложения (\texttt{TruncatedSVD}) из библиотеки \texttt{scikit-learn}. Классическое сингулярное разложение (SVD) представляется формулой
\[
R = U \Sigma V^T.
\]

Такое разложение можно понимать как разбиение исходной матрицы $R$ на набор \emph{основных направлений}, по которым данные изменяются сильнее всего. Эти направления задаются столбцами матриц $U$ и~$V$, а величины изменений вдоль них~— значениями диагональной матрицы $\Sigma$.

Каждое сингулярное значение показывает, насколько ``важна'' соответствующая компонента: чем оно больше, тем больший вклад эта компонента вносит в структуру данных. Если оставить только $k$ наибольших сингулярных значений, то мы получим приближение
\[
R \approx U_k \Sigma_k V_k^T,
\]
которое содержит только самые информативные латентные признаки.

Этот подход является оптимальным в следующем смысле: приближение ранга $k$, полученное таким образом, сохраняет \emph{максимально возможную} часть информации исходной матрицы среди всех возможных матриц ранга $k$. Поэтому такой метод хорошо подходит для задач, где нужно уменьшить размерность без существенной потери смысла данных.

Метод \texttt{TruncatedSVD} эффективно работает с разреженными матрицами и не требует преобразования в плотный формат. В итоге в данной работе были получены:
\begin{itemize}
	\item матрица эмбеддингов пользователей $U_k$ размером $(126\,588, 128)$;
	\item матрица эмбеддингов фильмов $V_k$ размером $(30\,521, 128)$.
\end{itemize}

Каждая из 128 координат в этих эмбеддингах соответствует одному из главных скрытых признаков, которые SVD сумело выделить из исходных оценок.


Полученные векторные представления являются конечным продуктом этапа предварительной подготовки и служат основой для построения моделей рекомендаций, основанных на вычислении сходства векторов в общем латентном пространстве.

\subsection*{Вывод по результатам генерации эмбеддингов}

В результате факторизации пользовательско-предметной матрицы методом усечённого сингулярного разложения (SVD) были получены плотные эмбеддинги пользователей и фильмов размерностью 128. Несмотря на крайне высокую разреженность исходной матрицы (0.76\% заполненности), метод позволил выделить ключевые латентные структуры данных, сохранив 42.07\% общей дисперсии оценок.

Созданные векторы имеют компактный размер: 153.43~МБ вместо 14.7~ГБ, которые потребовались бы для хранения плотной матрицы, что соответствует сжатию информации в 96 раз без существенной потери качества. Полученные эмбеддинги успешно используются для вычисления сходства между пользователями и фильмами в низкоразмерном пространстве и демонстрируют корректность рекомендаций на практике: для тестового пользователя были возвращены фильмы с ожидаемо высокими оценками и жанровой близостью.

Показатель «42\% объяснённой дисперсии» означает, что выбранные 128 латентных признаков сохраняют 42\% всей информации, содержащейся в исходной разреженной матрице оценок. Несмотря на то, что это значение меньше 100\%, его оказывается достаточно для построения рекомендаций. Это объясняется тем, что в реальных данных большая часть сигналов относится к шуму: оценки пользователей неоднородны, субъективны и часто неполны. Латентные компоненты SVD автоматически отбрасывают шумовые направления и сохраняют только наиболее устойчивые и значимые зависимости между пользователями и фильмами.

Таким образом, применение SVD позволило эффективно преобразовать исходные данные в информативное и вычислительно удобное представление, являющееся надёжной основой для построения рекомендательной системы.

\newpage

\section{Реализация}

\subsection{Реализация точного KNN}

Точный метод K-ближайших соседей был реализован с использованием класса NearestNeighbors из библиотеки scikit-learn. Данная реализация служит эталоном (ground truth) для оценки точности приближённых методов.

\textbf{Принцип работы}: Метод полного перебора (brute-force) вычисляет расстояния от запроса до всех точек в наборе данных и возвращает k ближайших. Этот подход гарантирует нахождение точных ближайших соседей, но требует больших вычислительных ресурсов при большом размере данных.

\textbf{Ключевые параметры:}
\begin{itemize}
	\item \texttt{metric='cosine'}~--- косинусное расстояние, наиболее подходящее для сравнения векторов оценок
	\item \texttt{algorithm='brute'}~--- полный перебор всех элементов для гарантии точности
	\item \texttt{n\_neighbors=20}~--- количество возвращаемых ближайших соседей
	\item \texttt{n\_jobs=-1}~--- использование всех доступных процессорных ядер
\end{itemize}

\textbf{Результаты построения индексов:}
\begin{itemize}
	\item Время построения user-based индекса: --- с
	\item Время построения item-based индекса: --- с
	\item Потребление памяти: --- MB (user-based), --- MB (item-based)
\end{itemize}

Быстрое построение индекса объясняется отсутствием предварительной обработки~--- метод brute-force не создаёт дополнительных структур данных, а работает напрямую с исходной матрицей.

\textbf{Производительность запросов:}
\begin{itemize}
	\item Среднее время запроса user-based: --- мс
	\item Среднее время запроса item-based: --- мс
\end{itemize}

Как видно из результатов, время выполнения запроса значительно превышает время построения индекса, что является характерной особенностью точного метода. Для каждого запроса вычисляются расстояния до всех пользователей (или фильмов), что приводит к линейной зависимости времени от размера датасета.

\textbf{Точность:}
\begin{itemize}
	\item Recall@20: 1.0000 (user-based и item-based)
	\item Precision@20: 1.0000 (user-based и item-based)
\end{itemize}

По определению, точный метод возвращает идеально корректные результаты, что подтверждается максимальными значениями метрик.

\subsection{Реализация приближённых методов поиска (Annoy, FAISS, HNSW)}

\subsubsection{Annoy (Approximate Nearest Neighbors Oh Yeah)}

Annoy~--- библиотека от Spotify, основанная на построении леса случайных проекционных деревьев.

\textbf{Принцип работы}: Для каждого дерева выбирается случайная гиперплоскость, разделяющая пространство на две части. Процесс рекурсивно повторяется, формируя бинарное дерево. При поиске запрос проходит по всем деревьям, и результаты объединяются. Этот метод позволяет быстро находить приближенные ближайшие соседи за счет уменьшения пространства поиска.

\textbf{Параметры реализации:}
\begin{itemize}
	\item \texttt{n\_trees=50}~--- количество деревьев в лесу
	\item \texttt{metric='angular'}~--- эквивалент косинусного расстояния
\end{itemize}

\textbf{Результаты:}
\begin{itemize}
	\item Время построения user-based: --- с
	\item Время построения item-based: --- с
	\item Потребление памяти: --- MB (user-based), --- MB (item-based)
	\item Среднее время запроса user-based: --- мс
	\item Среднее время запроса item-based: --- мс
	\item Recall@20 user-based: ---
	\item Recall@20 item-based: ---
	\item Precision@20 user-based: ---
	\item Precision@20 item-based: ---
\end{itemize}

\textbf{Анализ}: Annoy продемонстрировал значительное ускорение запросов (в $\sim$--- раз быстрее Exact KNN) при существенном снижении точности. Для user-based подхода точность составила всего ---\%, а для item-based~--- ---\%. Это связано с тем, что метод является приближенным и компромиссом между скоростью и точностью.

\subsubsection{FAISS (Facebook AI Similarity Search)}

FAISS~--- библиотека от Meta, оптимизированная для работы с большими объёмами данных и GPU-ускорением.

\textbf{Принцип работы}: Используется метод IVF (Inverted File Index)~--- пространство разбивается на кластеры (ячейки Вороного), и при поиске проверяются только ближайшие кластеры. Этот подход значительно уменьшает количество вычислений, так как не нужно проверять все точки в пространстве.

\textbf{Параметры реализации:}
\begin{itemize}
	\item \texttt{nlist=500}~--- целевое количество кластеров
	\item \texttt{nprobe=20}~--- количество кластеров, проверяемых при поиске
	\item L2-нормализация векторов для корректного вычисления косинусного сходства
\end{itemize}

\textbf{Результаты:}
\begin{itemize}
	\item Время построения user-based: --- с
	\item Время построения item-based: --- с
	\item Потребление памяти: --- MB (user-based), --- MB (item-based)
	\item Среднее время запроса user-based: --- мс
	\item Среднее время запроса item-based: --- мс
	\item Recall@20 user-based: ---
	\item Recall@20 item-based: ---
	\item Precision@20 user-based: ---
	\item Precision@20 item-based: ---
\end{itemize}

\textbf{Анализ}: FAISS показал хороший баланс между скоростью и точностью. Запросы выполняются в $\sim$--- раз быстрее Exact KNN, при этом достигнута высокая точность: ---\% для user-based и ---\% для item-based. Быстрое построение индекса и умеренное потребление памяти делают FAISS эффективным выбором для задач, требующих хорошего компромисса между скоростью и точностью.

\subsubsection{HNSW (Hierarchical Navigable Small World)}

HNSW~--- графовый алгоритм, строящий многослойную структуру связей между элементами.

\textbf{Принцип работы}: Создаётся иерархия графов, где верхние уровни содержат разреженные длинные связи для быстрой навигации, а нижние~--- плотные локальные связи для точного поиска. Этот подход напоминает принцип работы дорожных сетей, где скоростные магистрали (верхние уровни) позволяют быстро перемещаться на большие расстояния, а местные дороги (нижние уровни) обеспечивают точное достижение пункта назначения.

\textbf{Параметры реализации:}
\begin{itemize}
	\item \texttt{ef\_construction=400}~--- размер динамического списка при построении
	\item \texttt{M=32}~--- количество двунаправленных связей на элемент
\end{itemize}

\textbf{Результаты:}
\begin{itemize}
	\item Время построения user-based: --- с
	\item Время построения item-based: --- с
	\item Потребление памяти: --- MB (user-based), --- MB (item-based)
	\item Среднее время запроса user-based: --- мс
	\item Среднее время запроса item-based: --- мс
	\item Recall@20 user-based: ---
	\item Recall@20 item-based: ---
	\item Precision@20 user-based: ---
	\item Precision@20 item-based: ---
\end{itemize}

\textbf{Анализ}: HNSW продемонстрировал выдающийся баланс между скоростью и точностью. Время запросов в $\sim$--- раз меньше, чем у Exact KNN, при этом точность составляет ---\% и ---\% соответственно~--- фактически достигнута точность, близкая к эталонной. Это подтверждает теоретические преимущества графового подхода для задач поиска ближайших соседей.

\subsection{Методика оценки точности и производительности}

Для объективного сравнения алгоритмов была разработана комплексная система оценки, включающая четыре группы метрик:

\subsubsection{Метрики производительности}

\textbf{1. Время построения индекса}~--- измеряется для каждого алгоритма отдельно для user-based и item-based подходов. Отражает накладные расходы на предварительную обработку данных и создание вспомогательных структур.

\textbf{2. Время выполнения запроса}~--- усредняется по 100 случайным тестовым запросам. Ключевая метрика для production-систем, где требуется обработка запросов в реальном времени.

\textbf{3. Потребление оперативной памяти}~--- измеряется с использованием библиотеки psutil, фиксируется разница между начальным и конечным состоянием процесса. Важно для систем с ограниченными ресурсами.

\subsubsection{Метрики точности}

Для оценки качества приближённых методов используется сравнение с результатами Exact KNN:

\textbf{Recall@20}~--- доля правильно найденных соседей из топ-20:
$\text{Recall@20} = \frac{|\text{найденные соседи} \cap \text{истинные соседи}|}{|\text{истинные соседи}|}$

\textbf{Precision@20}~--- доля релевантных объектов среди возвращённых:
$\text{Precision@20} = \frac{|\text{найденные соседи} \cap \text{истинные соседи}|}{|\text{найденные соседи}|}$

В данном случае, так как оба множества содержат ровно 20 элементов, Recall@20 = Precision@20.

\subsubsection{Процедура тестирования}

\begin{enumerate}
    \item Генерация тестовой выборки из 100 случайных пользователей и 100 случайных фильмов
    \item Получение эталонных результатов от Exact KNN для всех тестовых запросов
    \item Выполнение тех же запросов для каждого приближённого метода
    \item Попарное сравнение результатов с использованием множественных операций
    \item Вычисление средних значений метрик по всем тестовым запросам
\end{enumerate}

\subsubsection{Визуализация результатов}

Результаты представлены в виде шести графиков:
\begin{enumerate}
    \item Время построения индекса~--- сравнение накладных расходов
    \item Потребление памяти~--- оценка ресурсоёмкости
    \item Среднее время запроса (логарифмическая шкала)~--- демонстрация различий в производительности
    \item Recall@20~--- оценка полноты результатов
    \item Precision@20~--- оценка точности результатов
    \item Компромисс скорость-точность~--- scatter-plot для выявления оптимальных алгоритмов
\end{enumerate}

Такой комплексный подход позволяет оценить каждый алгоритм с разных сторон и выбрать оптимальное решение в зависимости от приоритетов конкретной задачи.

\newpage

% ============ ЗАКЛЮЧЕНИЕ ============
\section{Заключение}

В рамках данной работы было проведено исследование эффективности различных реализаций алгоритма K-ближайших соседей для коллаборативной рекомендательной системы. Реализованы и протестированы четыре метода: точный KNN (scikit-learn), Annoy, FAISS и HNSW на датасете MovieLens.

\textbf{Основные результаты исследования:}

\textbf{Производительность построения индексов:}
\begin{itemize}
\item ---
\end{itemize}

\textbf{Производительность запросов:}
\begin{itemize}
\item ---
\end{itemize}

\textbf{Точность рекомендаций:}
\begin{itemize}
\item ---
\end{itemize}

\textbf{Потребление памяти:}
\begin{itemize}
\item ---
\end{itemize}

\newpage

\textbf{Выводы:}

Экспериментальные результаты подтвердили теоретические преимущества приближённых методов поиска ближайших соседей. ТУТ НАПИШУ КАКОЙ МЕТОД ЛУЧШЕ ВСЕХ И В КАКИХ СЛУЧАЯХ СТОИТ ИСПОЛЬЗОВАТЬ ОСТАЛЬНЫЕ

Разработанная система сравнения может быть использована для тестирования других алгоритмов и датасетов, а полученные результаты служат основой для выбора оптимального метода в зависимости от конкретных требований к производительности и точности рекомендательной системы.


% ============ СПИСОК ЛИТЕРАТУРЫ ============
\newpage
\begin{thebibliography}{99}
\addcontentsline{toc}{section}{Список литературы}

\bibitem{movielens}
MovieLens Dataset. GroupLens Research. URL: https://grouplens.org/datasets/movielens/



\end{thebibliography}

\end{document}