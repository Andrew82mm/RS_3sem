\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{indentfirst}

\geometry{
	a4paper,
	left=30mm,
	right=15mm,
	top=20mm,
	bottom=20mm
}

% Настройка гиперссылок
\hypersetup{
	colorlinks=true,
	linkcolor=black,
	citecolor=black,
	filecolor=black,
	urlcolor=blue
}

% Переименование заголовков
\addto\captionsrussian{
	\renewcommand{\contentsname}{Оглавление}
	\renewcommand{\refname}{Список литературы}
}

% Настройка отступов
\setlength{\parindent}{1.25cm}
\setlength{\parskip}{0pt}

\begin{document}
	
	% ============ ТИТУЛЬНЫЙ ЛИСТ ============
	\begin{titlepage}
		\centering
		
		{\large САНКТ-ПЕТЕРБУРГСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ\par}
		\vspace{0.5cm}
		{\large Искусственный интеллект и наука о данных\par}
		
		\vspace{4cm}
		
		{\large Сергиенко Андрей\par}
		
		\vspace{2cm}
		
		{\Large\bfseries Применение алгоритмов K-ближайших соседей в коллаборативных рекомендательных системах\par}
		
		\vspace{0.5cm}
		
		{\large Отчёт о прохождении\\Учебной (ознакомительной) практики\par}
		
		\vfill
		
		\begin{flushright}
			Научный руководитель:\\
			Старший преподаватель кафедры системного программирования\\
			Юрий Александрович Андреев
		\end{flushright}
		
		\vfill
		
		{\large Санкт-Петербург\par}
		{\large 2025\par}
		
	\end{titlepage}
	
	% ============ ОГЛАВЛЕНИЕ ============
	\newpage
	\tableofcontents
	\newpage
	
	% ============ ВВЕДЕНИЕ ============
	\section*{Введение}
	\addcontentsline{toc}{section}{Введение}
	
	Современные информационные системы ежедневно обрабатывают огромные объёмы данных, среди которых особое место занимают персонализированные рекомендации~--- фильмы, музыка, товары, новости и многое другое. Рекомендательные системы позволяют пользователям находить интересный контент, а компаниям~--- повышать вовлечённость и продажи.
	
	Одним из наиболее популярных подходов к построению рекомендательных систем является коллаборативная фильтрация (Collaborative Filtering, CF), основанная на идее, что пользователи с похожими интересами будут оценивать похожие объекты схожим образом. Ключевой задачей коллаборативной фильтрации является поиск похожих пользователей или объектов, для чего широко применяется алгоритм K-ближайших соседей (K-Nearest Neighbors, KNN).
	
	Однако точный поиск ближайших соседей имеют высокую вычислительную сложность и становится неэффективным при работе с большими наборами данных. Поэтому активно развиваются приближённые методы поиска ближайших соседей (Approximate Nearest Neighbors, ANN), такие как Annoy, FAISS и HNSW, обеспечивающие компромисс между скоростью и точностью.
	
	Настоящая работа посвящена исследованию и сравнению эффективности различных реализаций алгоритма K-ближайших соседей в контексте коллаборативных рекомендательных систем.
	
	\newpage
	
	% ============ ПОСТАНОВКА ЗАДАЧИ ============
	\section{Постановка задачи}
	
	Цель работы~--- исследовать эффективность различных алгоритмов K-ближайших соседей для реализации коллаборативной рекомендательной системы, а также провести сравнительный анализ их производительности, точности и использования памяти.
	
	Для достижения цели необходимо решить следующие задачи:
	
	\begin{enumerate}
		\item Изучить основные принципы работы коллаборативной фильтрации и алгоритма K-ближайших соседей.
		\item Реализовать базовую рекомендательную систему на основе пользовательских и предметных матриц.
		\item Реализовать и сравнить четыре метода поиска ближайших соседей:
		\begin{itemize}
			\item Точный KNN;
			\item Annoy;
			\item FAISS;
			\item HNSW (Hierarchical Navigable Small World).
		\end{itemize}
		\item Провести измерения времени построения индекса, скорости запросов, точности (Recall@20, Precision@20) и использования памяти.
		\item Визуализировать результаты и сформулировать выводы о применимости каждого метода.
	\end{enumerate}
	
	\subsection{Используемые библиотеки поиска ближайших соседей}
	
	Среди наиболее популярных библиотек для реализации ANN можно выделить:
	
	\begin{itemize}
		\item \textbf{Annoy}~--- метод случайных проекций и построения деревьев, эффективен для больших векторов признаков.
		\item \textbf{FAISS}~--- оптимизирована под большие данные и вычисления на GPU, активно используется в индустриальных решениях.
		\item \textbf{HNSW (Hierarchical Navigable Small World)}~--- графовая структура данных, обеспечивающая высокую точность и малое время отклика даже при миллионах элементов.
	\end{itemize}
	
	\subsection{Ожидаемые результаты}
	
	В ходе работы будет реализован программный комплекс для сравнения точного и приближённых алгоритмов поиска ближайших соседей в коллаборативных системах рекомендаций.
	
	Ожидается, что:
	\begin{itemize}
		\item Точный KNN обеспечит наилучшую точность (Recall@20, Precision@20), но низкую производительность на больших данных;
		\item Annoy покажет самое быстрое время запроса;
		\item FAISS продемонстрирует высокую скорость построения при больших объёмах данных.
		\item HNSW обеспечит оптимальный баланс между скоростью, точностью и памятью, являясь лучшим выбором для production-систем.
	\end{itemize}
	
	
	% ============ ОБЗОР ============
	\section{Обзор}
	
	\subsection{Обзор рекомендательных систем и их классификация}
	
	Рекомендательные системы предсказывают интерес пользователя к объекту на основе исторических данных. В данной работе используется коллаборативная фильтрация (CF), которая делится на user-based CF (поиск похожих пользователей) и item-based CF (поиск похожих объектов).
	
	\subsection{Алгоритм K-ближайших соседей и его применение}
	
	Алгоритм K-ближайших соседей (KNN) является одним из базовых методов в коллаборативной фильтрации. Он позволяет находить элементы, наиболее похожие на заданный, по метрике сходства (например, косинусное сходство или корреляция Пирсона).В user-based CF ищутся пользователи со схожим поведением, в item-based CF — схожие объекты. Рекомендации формируются как взвешенное усреднение оценок ближайших соседей.
	
	\subsection{Проблемы масштабируемости и приближённые методы}
	
	Основным недостатком точного KNN является высокая вычислительная сложность.
	
	Пусть у нас:
	\begin{itemize}
		\item $N$~--- количество объектов в базе
		\item $Q$~--- количество запросов
		\item $d$~--- размерность поискового пространства
		\item $K$~--- количество искомых соседей
	\end{itemize}
	
	Вычисление расстояния между двумя векторами требует $O(d)$.\\
	Так как нужно сравнить со всеми $N$ точками, то $O(N \cdot d)$.\\
	Для всех $Q$ запросов~--- $O(Q \cdot N \cdot d)$.\\
	Используем алгоритм Quickselect~--- $O(N + K \log K)$.\\
	После вычисления всех $N$ расстояний нужно выбрать $K$ наименьших~--- $O(Q \cdot (N \cdot d + K \log K))$.
	
	При росте числа пользователей, запросов и объектов (например, в системах с миллионами записей) такой подход становится непрактичным.
	
	Для решения этой проблемы используются Approximate Nearest Neighbors (ANN)~--- приближённые методы поиска, которые жертвуют небольшой долей точности ради значительного выигрыша в скорости.
	
	ANN-методы строят специальные структуры данных (деревья, графы, хеши), что позволяет находить близкие элементы за логарифмическое или даже константное время.
	
	
	% ============ ПРОЕКТИРОВАНИЕ ============
	\section{Проектирование}
	
	\subsection{Архитектура системы} 
	
	Архитектура разработанной системы для генерации эмбеддингов рекомендательной системы построена по модульному принципу и состоит из следующих основных компонентов: 
	
	\textbf{1. Модуль обработки данных}
	\begin{itemize}
		\item Загрузка файлов \texttt{movies.csv} и \texttt{ratings.csv} из \texttt{data/raw}, удаление неиспользуемых признаков и базовая проверка данных.
		\item Фильтрация активных пользователей (>\,50 оценок) и популярных фильмов (>\,10 оценок), формирование непрерывных маппингов ID.
		\item Построение разреженной матрицы «пользователь–фильм» (формат CSR).
		\item Матричная факторизация методом TruncatedSVD (128 компонент) и генерация эмбеддингов пользователей и фильмов.
		\item Сохранение эмбеддингов, маппингов и модели в \texttt{data/processed}.
	\end{itemize}
	
	\textbf{2. Модуль реализации алгоритмов поиска}
	\begin{itemize}
		\item Единый интерфейс для всех алгоритмов с методами build(), query\_user(), query\_item()
		\item Четыре алгоритма поиска ExactKNN, AnnoyKNN, FAISSKNN, HNSWKNN
		\item Поддержка как user-based, так и item-based подходов
	\end{itemize}
	
	\textbf{3. Модуль мониторинга производительности}
	\begin{itemize}
		\item Оркестратор запускает каждый алгоритм в отдельном воркер-процессе, что обеспечивает изолированные измерения времени и памяти.
		\item Воркеры строят индекс, выполняют тестовые запросы и передают результаты обратно оркестратору.
		\item Потребление оперативной памяти фиксируется с помощью \texttt{psutil}, замеры времени включают построение индекса и выполнение запросов.
	\end{itemize}
	
	
	\textbf{4. Модуль оценки точности и визуализации}
	\begin{itemize}
		\item Генерация тестовой выборки из 100 случайных запросов
		\item Сравнение результатов приближённых методов с эталонным Exact KNN
		\item Вычисление метрик Recall@20 и Precision@20
		\item Построение шести сравнительных графиков
		\item Сохранение результатов в CSV-формате
	\end{itemize}
	
	Взаимодействие между модулями организовано последовательно: данные проходят через этапы загрузки, обработки, построения индексов, тестирования и визуализации результатов.
	
	\subsection{Выбор и подготовка датасета}
	
	В качестве экспериментального датасета был выбран MovieLens(32m)~--- один из наиболее распространённых наборов данных для исследований в области рекомендательных систем. Датасет содержит:
	\begin{itemize}
		\item Файл movies.csv: идентификаторы фильмов, названия и жанры.
		\item Файл ratings.csv: оценки пользователей (userId, movieId, rating, timestamp).
	\end{itemize}
	
	На этапе предварительной обработки были выполнены следующие операции:
	
	\textbf{Удаление избыточных признаков}: столбцы `genres` и `timestamp` были исключены, так как в данной работе исследуется исключительно коллаборативная фильтрация без использования контентных признаков.
	
	\textbf{Фильтрация пользователей и объектов}: для повышения качества рекомендаций и уменьшения вычислительной сложности были отобраны только активные пользователи (с числом оценок $> 50$) и популярные фильмы (с числом оценок $> 10$). Это позволило снизить влияние шумовых взаимодействий и сосредоточиться на объектах с достаточным количеством информации для построения надёжных моделей. В результате было выделено 126 588 пользователей и 30 521 фильм.
	
	\subsection{Формирование пользовательско-предметной матрицы}
	
	Была сформирована матрица взаимодействий «пользователь–объект» размерностью 126 588 × 30 521 с разреженностью 99.24\% (плотность 0.76\%).
	Использование разреженного формата. Плотная матрица такого размера потребовала бы ~15.5 ГБ памяти, что непрактично. Матрица была конвертирована в формат CSR (Compressed Sparse Row), который хранит только ненулевые элементы, обеспечивая существенную экономию памяти и быструю индексацию строк.
	Необходимость снижения размерности. Несмотря на сжатие, работа с десятками тысяч признаков приводит к проблеме «проклятия размерности»: вычисление расстояний становится неинформативным, так как большинство пар пользователей не имеют пересечений по оценённым фильмам. Это делает невозможным эффективное использование разреженной матрицы для поиска соседей, требуя перехода к плотным низкоразмерным эмбеддингам.
	
	\subsection{Снижение размерности и генерация эмбеддингов}
	
	Для получения компактного представления был применён метод усечённого сингулярного разложения (TruncatedSVD). Эмбеддинг — плотный вектор фиксированного размера (128), кодирующий латентные признаки пользователя или фильма.
	Преимущества эмбеддингов:
	
	Снижение размерности с 30 521 до 128
	Вычислительная эффективность — расчёт сходства на порядки быстрее
	Борьба с разреженностью — можно определять сходство даже без совместных оценок
	Сжатие информации в 200+ раз с сохранением значимой части дисперсии
	
	Математическая основа. Классическое SVD: \( R = U \Sigma V^T \). При усечении до \( k \) компонент получаем оптимальное приближение:
	\( R \approx U_k \Sigma_k V_k^T \)
	где \( k = 128 \). TruncatedSVD эффективно работает с разреженными матрицами без преобразования в плотный формат.
	Результаты факторизации:
	
	Матрица эмбеддингов пользователей: (126 588, 128)
	Матрица эмбеддингов фильмов: (30 521, 128)
	Объяснённая дисперсия: 42.07%
	Размер данных: 153.43 МБ вместо 14.7 ГБ (сжатие в 96 раз)
	
	Показатель 42\% объяснённой дисперсии достаточен, так как SVD автоматически отбрасывает шумовые направления, сохраняя устойчивые зависимости между пользователями и фильмами. Несмотря на то, что это значение меньше 100\%, его оказывается достаточно для построения рекомендаций.
	
	\section{Реализация}
	
	\subsection{Архитектура системы}
	Все методы поиска реализованы через единый абстрактный класс с методами build(), query\_user(), query\_item().
	Архитектура измерений. Для точного измерения памяти используется архитектура изолированных процессов:
	\textbf{Orchestrator-процесс:}
	\begin{enumerate}
		\item Загружает эмбеддинги и генерирует 100 тестовых запросов (seed=42)
		\item Вычисляет ground truth через ExactKNN
		\item Запускает worker-процессы для каждого алгоритма
		\item Собирает результаты через JSON и генерирует отчёты
	\end{enumerate}
	\textbf{Worker-процесс:}
	\begin{enumerate}
		\item Загружает данные в изолированное адресное пространство
		\item Строит индекс с отслеживанием памяти через psutil
		\item Выполняет тестовые запросы и вычисляет метрики
		\item Отправляет результаты в stdout и завершается
	\end{enumerate}
	Такая архитектура полностью исключает влияние накладных расходов других методов, артефактов сборщика мусора Python и фрагментации памяти. Каждый worker-процесс завершается сразу после отправки результатов, освобождая все выделенные ресурсы. Это позволяет получить точные изолированные измерения потребления памяти для каждого алгоритма.
	
	\subsection{Оптимизация гиперпараметров}
	
	Перед финальным тестированием для всех приближённых методов была проведена процедура настройки гиперпараметров методом grid search. 
	Целью оптимизации является нахождение баланса между точностью и скоростью выполнения запросов.
	
	\subsubsection{Методология настройки}
	
	Для объективной оценки качества каждой комбинации параметров автором была разработана композитная метрика:
	
	\[
	\text{Score} = 0.4 \cdot \text{Recall@20} 
	- 0.6 \cdot \ln\!\left( 1 + \text{QueryTime}_{\text{ms}} \right).
	\]
	
	Эта формула балансирует два ключевых требования:
	\begin{itemize}
		\item \textbf{Точность} (вес 0.4): более высокий Recall@20 увеличивает итоговый скор;
		\item \textbf{Скорость} (вес 0.6): логарифм времени запроса вычитается, поэтому более быстрые алгоритмы получают преимущество.
	\end{itemize}
	
	Использование логарифма времени позволяет корректно обрабатывать различия в несколько порядков и избежать доминирования временной компоненты над точностью. 
	Веса 0.4/0.6 были выбраны эмпирически с приоритетом на производительность, что соответствует требованиям production-систем рекомендаций.
	
	\subsubsection{Пространство поиска параметров}
	
	Для каждого алгоритма определена сетка гиперпараметров, основанная на рекомендациях разработчиков библиотек и предварительных экспериментах.
	
	\textbf{Annoy:}
	\begin{itemize}
		\item \texttt{n\_trees} $\in \{25, 50, 100, 200\}$ --- количество деревьев в лесу.
	\end{itemize}
	
	\textbf{FAISS:}
	\begin{itemize}
		\item \texttt{nlist} $\in \{100, 400, 800, 1600\}$ --- количество кластеров для IVF-индекса.
	\end{itemize}
	
	\textbf{HNSW:}
	\begin{itemize}
		\item \texttt{ef\_construction} $\in \{200, 400, 800\}$ --- размер динамического списка при построении;
		\item \texttt{M} $\in \{16, 32, 48\}$ --- количество двунаправленных связей на элемент;
	\end{itemize}
	
	\subsubsection{Результаты настройки}
	
	Процедура grid search выполнена на той же тестовой выборке из 100 запросов, что использовалась для финального сравнения. 
	Для каждой комбинации параметров вычислены Recall@20, среднее время запроса и композитный скор.
	
	\textbf{Annoy} --- протестировано 4 конфигурации:
	\begin{itemize}
		\item Лучшая конфигурация: \texttt{n\_trees=50}, Score = 0.199;
	\end{itemize}
	
	\textbf{FAISS} --- протестировано 4 конфигурации:
	\begin{itemize}
		\item Лучшая конфигурация: \texttt{nlist=1600}, Score = 0.291;
	\end{itemize}
	
	\textbf{HNSW} --- протестировано 9 комбинаций:
	\begin{itemize}
		\item Лучшая конфигурация: \texttt{ef\_construction=200}, \texttt{M=16}, Score = 0.327;
	\end{itemize}
	
	Все результаты сохранены в файл \texttt{tuning/tuning\_results.csv} для последующего анализа. 
	Найденные оптимальные параметры зафиксированы в конфигурационном файле \texttt{tuning/best\_params.json} и использованы для финального тестирования приближённых методов.
	
	\subsection{Методика оценки точности и производительности}
	Для объективного сравнения алгоритмов была разработана комплексная система оценки, включающая четыре группы метрик:
	
	\subsubsection{Метрики производительности}
	\textbf{1. Время построения индекса}~--- измеряется для каждого алгоритма отдельно для user-based и item-based подходов. Отражает накладные расходы на предварительную обработку данных и создание вспомогательных структур.
	
	\textbf{2. Время выполнения запроса}~--- усредняется по 100 случайным тестовым запросам. Ключевая метрика для production-систем, где требуется обработка запросов в реальном времени.
	
	\textbf{3. Потребление оперативной памяти}~--- измеряется с использованием архитектуры изолированных процессов. Каждый алгоритм запускается в отдельном subprocess через модуль subprocess, что позволяет точно измерить приращение памяти без влияния артефактов других методов и сборщика мусора Python. Важно для систем с ограниченными ресурсами.
	
	\subsubsection{Метрики точности}
	Для оценки качества приближённых методов используется сравнение с результатами Exact KNN:
	\textbf{Recall@20}~--- доля правильно найденных соседей из топ-20:
	
	$\text{Recall@20} = \frac{|\text{найденные соседи} \cap \text{истинные соседи}|}{|\text{истинные соседи}|}$
	
	\textbf{Precision@20}~--- доля релевантных объектов среди возвращённых:
	
	$\text{Precision@20} = \frac{|\text{найденные соседи} \cap \text{истинные соседи}|}{|\text{найденные соседи}|}$
	
	В данном случае, так как оба множества содержат ровно 20 элементов, Recall@20 = Precision@20
	
	\subsubsection{Процедура тестирования}
	\begin{enumerate}
		\item Генерация 100 случайных тестовых запросов (seed=42)
		\item Получение эталонных результатов от Exact KNN для всех тестовых запросов
		\item Запуск каждого алгоритма в изолированном subproces
		\item Попарное сравнение результатов с ground truth
		\item Вычисление средних значений метрик
	\end{enumerate}
	
	\subsubsection{Визуализация результатов}
	
	Результаты будут представлены в виде шести графиков: время построения индекса, потребление памяти, среднее время запроса (лог. шкала), Recall@20, Precision@20 и компромисс скорость-точность (scatter-plot).
	
	\newpage
	
	\subsection{Реализация точного KNN}
	
	Точный метод K-ближайших соседей был реализован с использованием класса NearestNeighbors из библиотеки scikit-learn. Данная реализация служит эталоном (ground truth) для оценки точности приближённых методов.
	
	\textbf{Принцип работы}: Метод полного перебора (brute-force) вычисляет расстояния от запроса до всех точек в наборе данных и возвращает k ближайших. Этот подход гарантирует нахождение точных ближайших соседей, но требует больших вычислительных ресурсов при большом размере данных.
	
	\textbf{Ключевые параметры:}
	\begin{itemize}
		\item \texttt{metric='cosine'}~--- косинусное расстояние, наиболее подходящее для сравнения векторов оценок
		\item \texttt{algorithm='brute'}~--- полный перебор всех элементов для гарантии точности
		\item \texttt{n\_neighbors=20}~--- количество возвращаемых ближайших соседей
		\item \texttt{n\_jobs=-1}~--- использование всех доступных процессорных ядер
	\end{itemize}
	
	\textbf{Результаты построения индексов:}
	\begin{itemize}
		\item Время построения user-based индекса: 0.0056 с
		\item Время построения item-based индекса: 0.0015 с
		\item Потребление памяти: 0.00 MB (измеримых накладных расходов не обнаружено)
	\end{itemize}
	
	Быстрое построение индекса объясняется отсутствием предварительной обработки~--- метод brute-force не создаёт дополнительных структур данных, а работает напрямую с исходной матрицей эмбеддингов.
	
	\textbf{Производительность запросов:}
	\begin{itemize}
		\item Среднее время запроса user-based: 139.59 мс
		\item Среднее время запроса item-based: 29.36 мс
	\end{itemize}
	Как видно из результатов, время выполнения запроса в десятки тысяч раз превышает время построения индекса, что является характерной особенностью точного метода. Для каждого запроса вычисляются расстояния до всех пользователей (или фильмов), что приводит к линейной зависимости времени от размера датасета. Различие во времени между user-based и item-based запросами объясняется разным размером пространств (количеством пользователей и фильмов).
	
	\textbf{Точность:}
	\begin{itemize}
		\item Recall@20: 1.0000 (user-based и item-based)
		\item Precision@20: 1.0000 (user-based и item-based)
	\end{itemize}
	
	По определению, точный метод возвращает идеально корректные результаты, что подтверждается максимальными значениями метрик.
	
	\subsection{Реализация приближённых методов поиска (Annoy, FAISS, HNSW)}
	\textbf{Для всех реализаций используются оптимальные параметры полученные в ходе тюнинга}
	\subsubsection{Annoy (Approximate Nearest Neighbors Oh Yeah)}
	
	Annoy~--- библиотека от Spotify, основанная на построении леса случайных проекционных деревьев.
	
	\textbf{Принцип работы}: Для каждого дерева выбирается случайная гиперплоскость, разделяющая пространство на две части. Процесс рекурсивно повторяется, формируя бинарное дерево. При поиске запрос проходит по всем деревьям, и результаты объединяются. Этот метод позволяет быстро находить приближенные ближайшие соседи за счет уменьшения пространства поиска.
	
	\textbf{Результаты:}
	\begin{itemize}
		\item Время построения user-based: 2.78 с
		\item Время построения item-based: 0.43 с
		\item Потребление памяти: 314.74 MB
		\item Среднее время запроса user-based: 0.19 мс
		\item Среднее время запроса item-based: 0.14 мс
		\item Recall@20 user-based: 0.760
		\item Recall@20 item-based: 0.922
		\item Precision@20 user-based: 0.760
		\item Precision@20 item-based: 0.922
	\end{itemize}
	
	\textbf{Анализ}: Annoy продемонстрировал наибольшее ускорение запросов (в $\sim$734 раза быстрее Exact KNN для user-based, в $\sim$209 раз для item-based) при умеренном снижении точности. Однако метод показал наибольшее потребление памяти среди всех приближённых алгоритмов (314.74 MB), что связано с хранением множественных деревьев. Точность user-based поиска (76.0\%) существенно ниже, чем у конкурентов, что может быть критичным для некоторых применений.
	
	\subsubsection{FAISS}
	
	FAISS~--- библиотека оптимизированная для работы с большими объёмами данных и GPU-ускорением.
	
	\textbf{Принцип работы}: Используется метод IVF (Inverted File Index)~--- пространство разбивается на кластеры (ячейки Вороного), и при поиске проверяются только ближайшие кластеры. Этот подход значительно уменьшает количество вычислений, так как не нужно проверять все точки в пространстве.
	
	\textbf{Результаты:}
	\begin{itemize}
		\item Время построения user-based: 8.54 с
		\item Время построения item-based: 2.04 с
		\item Потребление памяти: 131.54 MB
		\item Среднее время запроса user-based: 0.18 мс
		\item Среднее время запроса item-based: 0.06 мс
		\item Recall@20 user-based: 0.939
		\item Recall@20 item-based: 0.985
		\item Precision@20 user-based: 0.939
		\item Precision@20 item-based: 0.985
	\end{itemize}
	
	\textbf{Анализ}: FAISS показал хороший баланс между скоростью и точностью. Запросы выполняются в $\sim$775 раз быстрее Exact KNN для user-based и в $\sim$489 раз для item-based, при этом достигнута высокая точность: 93.9\% для user-based и 98.5\% для item-based. Умеренное потребление памяти (131.54 MB) и стабильно высокая точность делают FAISS эффективным выбором для production-систем, требующих надёжного компромисса между всеми характеристиками.
	
	\subsubsection{HNSW (Hierarchical Navigable Small World)}
	
	HNSW~--- графовый алгоритм, строящий многослойную структуру связей между элементами.
	
	\textbf{Принцип работы}: Создаётся иерархия графов, где верхние уровни содержат разреженные длинные связи для быстрой навигации, а нижние~--- плотные локальные связи для точного поиска. Этот подход напоминает принцип работы дорожных сетей, где скоростные магистрали (верхние уровни) позволяют быстро перемещаться на большие расстояния, а местные дороги (нижние уровни) обеспечивают точное достижение пункта назначения.
	
	\textbf{Результаты:}
	\begin{itemize}
		\item Время построения user-based: 7.27 с
		\item Время построения item-based: 0.45 с
		\item Потребление памяти: 121.05 MB
		\item Среднее время запроса user-based: 0.12 мс
		\item Среднее время запроса item-based: 0.06 мс
		\item Recall@20 user-based: 0.973
		\item Recall@20 item-based: 0.998
		\item Precision@20 user-based: 0.973
		\item Precision@20 item-based: 0.998
	\end{itemize}
	\textbf{Анализ}: HNSW продемонстрировал выдающийся баланс между скоростью и точностью. Метод обеспечивает максимальное ускорение запросов среди всех протестированных алгоритмов (в $\sim$1163 раза быстрее Exact KNN для user-based, в $\sim$489 раз для item-based) при наивысшей точности: 97.3\% и 99.8\% соответственно~--- фактически достигнута точность, близкая к эталонной. При этом HNSW демонстрирует минимальное потребление памяти среди приближённых методов (121.05 MB). Это подтверждает теоретические преимущества графового подхода для задач поиска ближайших соседей и делает HNSW оптимальным выбором для высоконагруженных систем.
	
	\subsection{Анализ разброса показателей производительности и потребления ресурсов}
	
	При повторных запусках сравнения (даже при фиксированном seed) значения Recall@K и Precision@K остаются одинаковыми, тогда как время и потребление памяти могут незначительно колебаться. Эти отклонения связаны с особенностями работы операционной системы и аппаратной среды.
	
	\subsubsection{Работа планировщика задач операционной системы}
	
	ОС распределяет процессорное время между множеством процессов, поэтому повторные измерения не дают полностью идентичные результаты.
	
	\begin{itemize}
		\item \textbf{Переключения контекста.} Во время выполнения программа может быть временно приостановлена системными службами, что увеличивает общее время работы.
		\item \textbf{Файловый кэш.} Доступ к данным может быть быстрее, если файлы уже находятся в кэше ОС, и медленнее при первом чтении.
	\end{itemize}
	
	\subsubsection{Особенности работы процессора}
	
	Современные процессоры динамически изменяют частоту в зависимости от нагрузки и температуры. Из-за этого вычислительно тяжёлые этапы (например, построение индексов HNSW или FAISS) могут занимать немного разное время при разных запусках.
	
	\subsubsection{Аллокация памяти и специфика измерений}
	
	\begin{itemize}
		\item \textbf{Фрагментация памяти.} Память выделяется блоками, и порядок аллокаций между запусками может отличаться, что приводит к небольшим различиям в зафиксированных значениях.
		\item \textbf{Периодичность замеров.} Инструменты профилирования считывают данные с определённым интервалом, поэтому точный момент максимального потребления памяти может быть пропущен.
	\end{itemize}
	
	
	
	% ============ ЗАКЛЮЧЕНИЕ ============
	\section{Заключение}
	
	В ходе работы был выполнен комплексный анализ эффективности разных реализаций алгоритма $k$-ближайших соседей (KNN) в задаче коллаборативных рекомендаций. На датасете MovieLens были протестированы четыре подхода: точный KNN (scikit-learn) и три приближённых метода — Annoy, FAISS и HNSW.  
	Эксперименты показали, что для построения масштабируемых систем реального времени предпочтительно использовать приближённые алгоритмы: они дают огромный выигрыш в скорости, при этом потеря точности остаётся небольшой.
	
	\subsection{Рекомендации по выбору метода}
	
	Каждый протестированный алгоритм имеет свои сильные стороны. Выбор конкретного варианта зависит от требований к задержке, уровню точности, доступной памяти и размера данных.
	
	\subsubsection{1. Точный KNN (Brute-Force)}
	
	\textbf{Характеристики:}  
	Обеспечивает максимальную точность (Recall@20 = 1.0), быстро строится и не требует отдельного индекса. Главный недостаток — очень медленные запросы при увеличении размера датасета: десятки–сотни миллисекунд на один запрос.
	
	\textbf{Когда использовать:}  
	Подходит только для небольших наборов данных или офлайн-аналитики, где скорость запроса не критична. Чаще всего используется как \emph{эталон} для оценки точности приближённых методов.
	
	\subsubsection{2. Annoy}
	
	\textbf{Характеристики:}  
	Обеспечивает максимальную скорость запросов, но точность ниже, чем у других ANN-методов (Recall@20 = 0.760 для user-based). Потребляет больше всего памяти. Качество сильно зависит от числа деревьев.
	
	\textbf{Когда использовать:}  
	Подходит для задач, где важнее всего скорость запроса, а небольшие ошибки допустимы: предварительная фильтрация, подбор похожих товаров и т.п. Не рекомендуется для персональных лент, где точность критически важна.
	
	\subsubsection{3. FAISS}
	
	\textbf{Характеристики:}  
	Даёт хороший баланс между точностью и скоростью (Recall@20 = 0.939). Хорошо оптимизирован и поддерживает вычисления на GPU. Памяти требует умеренно.
	
	\textbf{Когда использовать:}  
	Отличный выбор для крупных систем: сочетает высокую производительность и стабильность. Особенно полезен, если есть доступ к GPU и требуется обработка больших объёмов данных.
	
	\subsubsection{4. HNSW}
	
	\textbf{Характеристики:}  
	Показал наилучший результат: почти эталонная точность (Recall@20 = 0.973) при самой высокой скорости среди всех методов. Потребляет меньше всего памяти из приближённых алгоритмов.
	
	\textbf{Когда использовать:}  
	Идеален для систем реального времени с высокой нагрузкой, где требуется минимальная задержка и высокая точность. Подходит как для больших сервисов, так и для ограниченных по ресурсам сред. На практике является де-факто стандартом для современных рекомендательных систем.
	
	
	
	% ============ СПИСОК ЛИТЕРАТУРЫ ============
\newpage
\begin{thebibliography}{99}
	\addcontentsline{toc}{section}{Список литературы}
	
	\bibitem{movielens}
	MovieLens Dataset. GroupLens Research.  
	URL: \url{https://grouplens.org/datasets/movielens/}
	
	\bibitem{sklearn_knn}
	Scikit-learn KNN.  
	URL: \url{https://scikit-learn.org/stable/modules/neighbors.html}
	
	\bibitem{annoy}
	Annoy source code.  
	URL: \url{https://github.com/spotify/annoy}
	
	\bibitem{faiss}
	FAISS documentation.  
	URL: \url{https://arxiv.org/pdf/1702.08734}
	
	\bibitem{hnsw}
	HNSW documentation.  
	URL: \url{https://arxiv.org/pdf/1603.09320}
	
	\bibitem{item_cf}
	Item-based Collaborative Filtering Recommendation Algorithms.  
	URL: \url{https://www.researchgate.net/publication/2369002_Item-based_Collaborative_Filtering_Recommendation_Algorithms}
	
	\bibitem{rs_handbook}
	Recommender Systems Handbook.  
	URL: \url{https://www.researchgate.net/publication/227268858_Recommender_Systems_Handbook}
	
	\bibitem{matrix factorization}
	Matrix factorization techniques for recommender systems
	URL: \url{https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf}
	
	\bibitem{knn and ann comparasion}
	A Comprehensive Survey and Experimental Comparison of Graph-Based Approximate Nearest Neighbor Search  
	URL: \url{https://arxiv.org/abs/2101.12631}
	
\end{thebibliography}

	
\end{document}